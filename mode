import matplotlib
matplotlib.use('Agg')

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

def load_data(file_path):
    try:
        data = pd.read_csv(file_path)
        print("Dataset loaded successfully.")
        return data
    except FileNotFoundError:
        print(f"Error: The file {file_path} was not found.")
        return None

def handle_missing_values(data):
    for column in data.select_dtypes(include=['float64', 'int64']).columns:
        data[column].fillna(data[column].mean(), inplace=True)
    
    for column in data.select_dtypes(include=['object']).columns:
        data[column].fillna(data[column].mode()[0], inplace=True)
    
    print("Missing values handled.")
    return data

def prepare_data(data):
    features = data[['age', 'gender', 'socioeconomic_status', 'GPA', 'test_scores', 'attendance_rate']]
    target = data['enrollment_status']
    
    features = pd.get_dummies(features, drop_first=True)
    
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    print("Data prepared for training.")
    
    return X_train, X_test, y_train, y_test

def tune_hyperparameters(X_train, y_train):
    param_grid = {
        'n_estimators': [50, 100],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }
    
    model = RandomForestClassifier(random_state=42)
    
    print("Tuning hyperparameters...")
    grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, scoring='accuracy')
    grid_search.fit(X_train, y_train)
    
    best_model = grid_search.best_estimator_
    print("Best parameters found:", grid_search.best_params_)
    
    return best_model

def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    
    print(f"Accuracy: {accuracy_score(y_test, predictions):.2f}")
    print("Classification Report:")
    print(classification_report(y_test, predictions))

def plot_feature_importance(model, features):
    importances_df = pd.DataFrame({
        'Feature': features.columns,
        'Importance': model.feature_importances_
    }).sort_values(by='Importance', ascending=False)

    plt.figure(figsize=(8, 6))
    sns.barplot(x='Importance', y='Feature', data=importances_df, palette='viridis')
    plt.title('Feature Importance')
    plt.xlabel('Importance Score')
    plt.ylabel('Features')
    plt.tight_layout()
    plt.savefig('feature_importance.png')
    plt.close()
    print("Feature importance plot saved as 'feature_importance.png'.")

def main():
    data = load_data('student_data.csv')
    if data is not None:
        data = handle_missing_values(data)
        X_train, X_test, y_train, y_test = prepare_data(data)
        model = tune_hyperparameters(X_train, y_train)
        evaluate_model(model, X_test, y_test)
        plot_feature_importance(model, X_train)

if __name__ == "__main__":
    main()
